{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18819a33",
   "metadata": {
    "papermill": {
     "duration": 0.004157,
     "end_time": "2025-12-01T10:04:32.893493",
     "exception": false,
     "start_time": "2025-12-01T10:04:32.889336",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Need for a uniform interface of running models\n",
    "\n",
    "As described in the official competition page, to win the prize money, a prerequisite is that the code has to be made open-source. In addition, the top 10 submissions/teams will be invited to become co-authors in a scientific paper that involves further stress-testing of their models in a subsequent phase with many other datasets outside Kaggle platform. **To enable such further analyses and re-use of the models by the community, we strongly encourage** the participants to adhere to a code template that we provide through this repository that enables a uniform interface of running models: [https://github.com/uio-bmi/predict-airr](https://github.com/uio-bmi/predict-airr)\n",
    "\n",
    "\n",
    "Ideally, all the methods can be run in a unified way, e.g.,\n",
    "\n",
    "`python3 -m submission.main --train_dir /path/to/train_dir --test_dirs /path/to/test_dir_1 /path/to/test_dir_2 --out_dir /path/to/output_dir --n_jobs 4 --device cpu`\n",
    "\n",
    "## Adhering to code template on Kaggle Notebooks\n",
    "\n",
    "Those participants who make use of Kaggle resources and Kaggle notebooks to develop and run their code are also strongly encouraged to copy the code template, particularly the `ImmuneStatePredictor` class and any utility functions from the provided code template repository and adhere to the code template to enable a unified way of running different methods at a later stage. In this notebook, we copied the code template below for participants to paste into their respective Kaggle notebooks and edit as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0037e570",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T10:04:32.903193Z",
     "iopub.status.busy": "2025-12-01T10:04:32.902091Z",
     "iopub.status.idle": "2025-12-01T10:04:48.658073Z",
     "shell.execute_reply": "2025-12-01T10:04:48.657161Z"
    },
    "papermill": {
     "duration": 15.76265,
     "end_time": "2025-12-01T10:04:48.659855",
     "exception": false,
     "start_time": "2025-12-01T10:04:32.897205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## imports required for the basic code template below.\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import sys\n",
    "import argparse\n",
    "import gc\n",
    "import pickle\n",
    "import hashlib\n",
    "from collections import defaultdict, Counter\n",
    "from typing import Iterator, Tuple, Union, List, Dict\n",
    "from scipy.stats import entropy, skew\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.base import clone\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff92c74e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T10:04:48.669858Z",
     "iopub.status.busy": "2025-12-01T10:04:48.669072Z",
     "iopub.status.idle": "2025-12-01T10:04:48.701387Z",
     "shell.execute_reply": "2025-12-01T10:04:48.699833Z"
    },
    "papermill": {
     "duration": 0.040329,
     "end_time": "2025-12-01T10:04:48.703610",
     "exception": false,
     "start_time": "2025-12-01T10:04:48.663281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## some utility functions such as data loaders, etc.\n",
    "\n",
    "def load_data_generator(data_dir: str, metadata_filename='metadata.csv') -> Iterator[\n",
    "    Union[Tuple[str, pd.DataFrame, bool], Tuple[str, pd.DataFrame]]]:\n",
    "    \"\"\"\n",
    "    A generator to load immune repertoire data.\n",
    "\n",
    "    This function operates in two modes:\n",
    "    1.  If metadata is found, it yields data based on the metadata file.\n",
    "    2.  If metadata is NOT found, it uses glob to find and yield all '.tsv'\n",
    "        files in the directory.\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): The path to the directory containing the data.\n",
    "\n",
    "    Yields:\n",
    "        An iterator of tuples. The format depends on the mode:\n",
    "        - With metadata: (repertoire_id, pd.DataFrame, label_positive)\n",
    "        - Without metadata: (filename, pd.DataFrame)\n",
    "    \"\"\"\n",
    "    metadata_path = os.path.join(data_dir, metadata_filename)\n",
    "\n",
    "    if os.path.exists(metadata_path):\n",
    "        metadata_df = pd.read_csv(metadata_path)\n",
    "        for row in metadata_df.itertuples(index=False):\n",
    "            file_path = os.path.join(data_dir, row.filename)\n",
    "            try:\n",
    "                repertoire_df = pd.read_csv(file_path, sep='\\t')\n",
    "                yield row.repertoire_id, repertoire_df, row.label_positive\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Warning: File '{row.filename}' listed in metadata not found. Skipping.\")\n",
    "                continue\n",
    "    else:\n",
    "        search_pattern = os.path.join(data_dir, '*.tsv')\n",
    "        tsv_files = glob.glob(search_pattern)\n",
    "        for file_path in sorted(tsv_files):\n",
    "            try:\n",
    "                filename = os.path.basename(file_path)\n",
    "                repertoire_df = pd.read_csv(file_path, sep='\\t')\n",
    "                yield filename, repertoire_df\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not read file '{file_path}'. Error: {e}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "\n",
    "def load_full_dataset(data_dir: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads all TSV files from a directory and concatenates them into a single DataFrame.\n",
    "\n",
    "    This function handles two scenarios:\n",
    "    1. If metadata.csv exists, it loads data based on the metadata and adds\n",
    "       'repertoire_id' and 'label_positive' columns.\n",
    "    2. If metadata.csv does not exist, it loads all .tsv files and adds\n",
    "       a 'filename' column as an identifier.\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): The path to the data directory.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A single, concatenated DataFrame containing all the data.\n",
    "    \"\"\"\n",
    "    metadata_path = os.path.join(data_dir, 'metadata.csv')\n",
    "    df_list = []\n",
    "    data_loader = load_data_generator(data_dir=data_dir)\n",
    "\n",
    "    if os.path.exists(metadata_path):\n",
    "        metadata_df = pd.read_csv(metadata_path)\n",
    "        total_files = len(metadata_df)\n",
    "        for rep_id, data_df, label in tqdm(data_loader, total=total_files, desc=\"Loading files\"):\n",
    "            data_df['ID'] = rep_id\n",
    "            data_df['label_positive'] = label\n",
    "            df_list.append(data_df)\n",
    "    else:\n",
    "        search_pattern = os.path.join(data_dir, '*.tsv')\n",
    "        total_files = len(glob.glob(search_pattern))\n",
    "        for filename, data_df in tqdm(data_loader, total=total_files, desc=\"Loading files\"):\n",
    "            data_df['ID'] = os.path.basename(filename).replace(\".tsv\", \"\")\n",
    "            df_list.append(data_df)\n",
    "\n",
    "    if not df_list:\n",
    "        print(\"Warning: No data files were loaded.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    full_dataset_df = pd.concat(df_list, ignore_index=True)\n",
    "    return full_dataset_df\n",
    "\n",
    "\n",
    "def load_and_encode_kmers(data_dir: str, k: int = 3) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Loading and k-mer encoding of repertoire data.\n",
    "\n",
    "    Args:\n",
    "        data_dir: Path to data directory\n",
    "        k: K-mer length\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (encoded_features_df, metadata_df)\n",
    "        metadata_df always contains 'ID', and 'label_positive' if available\n",
    "    \"\"\"\n",
    "    from collections import Counter\n",
    "\n",
    "    metadata_path = os.path.join(data_dir, 'metadata.csv')\n",
    "    data_loader = load_data_generator(data_dir=data_dir)\n",
    "\n",
    "    repertoire_features = []\n",
    "    metadata_records = []\n",
    "\n",
    "    search_pattern = os.path.join(data_dir, '*.tsv')\n",
    "    total_files = len(glob.glob(search_pattern))\n",
    "\n",
    "    for item in tqdm(data_loader, total=total_files, desc=f\"Encoding {k}-mers\"):\n",
    "        if os.path.exists(metadata_path):\n",
    "            rep_id, data_df, label = item\n",
    "        else:\n",
    "            filename, data_df = item\n",
    "            rep_id = os.path.basename(filename).replace(\".tsv\", \"\")\n",
    "            label = None\n",
    "\n",
    "        kmer_counts = Counter()\n",
    "        for seq in data_df['junction_aa'].dropna():\n",
    "            for i in range(len(seq) - k + 1):\n",
    "                kmer_counts[seq[i:i + k]] += 1\n",
    "\n",
    "        repertoire_features.append({\n",
    "            'ID': rep_id,\n",
    "            **kmer_counts\n",
    "        })\n",
    "\n",
    "        metadata_record = {'ID': rep_id}\n",
    "        if label is not None:\n",
    "            metadata_record['label_positive'] = label\n",
    "        metadata_records.append(metadata_record)\n",
    "\n",
    "        del data_df, kmer_counts\n",
    "\n",
    "    features_df = pd.DataFrame(repertoire_features).fillna(0).set_index('ID')\n",
    "    features_df.fillna(0)\n",
    "    metadata_df = pd.DataFrame(metadata_records)\n",
    "\n",
    "    return features_df, metadata_df\n",
    "\n",
    "\n",
    "def save_tsv(df: pd.DataFrame, path: str):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    df.to_csv(path, sep='\\t', index=False)\n",
    "\n",
    "\n",
    "def get_repertoire_ids(data_dir: str) -> list:\n",
    "    \"\"\"\n",
    "    Retrieves repertoire IDs from the metadata file or filenames in the directory.\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): The path to the data directory.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of repertoire IDs.\n",
    "    \"\"\"\n",
    "    metadata_path = os.path.join(data_dir, 'metadata.csv')\n",
    "\n",
    "    if os.path.exists(metadata_path):\n",
    "        metadata_df = pd.read_csv(metadata_path)\n",
    "        repertoire_ids = metadata_df['repertoire_id'].tolist()\n",
    "    else:\n",
    "        search_pattern = os.path.join(data_dir, '*.tsv')\n",
    "        tsv_files = glob.glob(search_pattern)\n",
    "        repertoire_ids = [os.path.basename(f).replace('.tsv', '') for f in sorted(tsv_files)]\n",
    "\n",
    "    return repertoire_ids\n",
    "\n",
    "\n",
    "def generate_random_top_sequences_df(n_seq: int = 50000) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generates a random DataFrame simulating top important sequences.\n",
    "\n",
    "    Args:\n",
    "        n_seq (int): Number of sequences to generate.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with columns 'ID', 'dataset', 'junction_aa', 'v_call', 'j_call'.\n",
    "    \"\"\"\n",
    "    seqs = set()\n",
    "    while len(seqs) < n_seq:\n",
    "        seq = ''.join(np.random.choice(list('ACDEFGHIKLMNPQRSTVWY'), size=15))\n",
    "        seqs.add(seq)\n",
    "    data = {\n",
    "        'junction_aa': list(seqs),\n",
    "        'v_call': ['TRBV20-1'] * n_seq,\n",
    "        'j_call': ['TRBJ2-7'] * n_seq,\n",
    "        'importance_score': np.random.rand(n_seq)\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "def validate_dirs_and_files(train_dir: str, test_dirs: List[str], out_dir: str) -> None:\n",
    "    assert os.path.isdir(train_dir), f\"Train directory `{train_dir}` does not exist.\"\n",
    "    train_tsvs = glob.glob(os.path.join(train_dir, \"*.tsv\"))\n",
    "    assert train_tsvs, f\"No .tsv files found in train directory `{train_dir}`.\"\n",
    "    metadata_path = os.path.join(train_dir, \"metadata.csv\")\n",
    "    assert os.path.isfile(metadata_path), f\"`metadata.csv` not found in train directory `{train_dir}`.\"\n",
    "\n",
    "    for test_dir in test_dirs:\n",
    "        assert os.path.isdir(test_dir), f\"Test directory `{test_dir}` does not exist.\"\n",
    "        test_tsvs = glob.glob(os.path.join(test_dir, \"*.tsv\"))\n",
    "        assert test_tsvs, f\"No .tsv files found in test directory `{test_dir}`.\"\n",
    "\n",
    "    try:\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        test_file = os.path.join(out_dir, \"test_write_permission.tmp\")\n",
    "        with open(test_file, \"w\") as f:\n",
    "            f.write(\"test\")\n",
    "        os.remove(test_file)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to create or write to output directory `{out_dir}`: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "def concatenate_output_files(out_dir: str) -> None:\n",
    "    \"\"\"\n",
    "    Concatenates all test predictions and important sequences TSV files from the output directory.\n",
    "\n",
    "    This function finds all files matching the patterns:\n",
    "    - *_test_predictions.tsv\n",
    "    - *_important_sequences.tsv\n",
    "\n",
    "    and concatenates them to match the expected output format of submissions.csv.\n",
    "\n",
    "    Args:\n",
    "        out_dir (str): Path to the output directory containing the TSV files.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Concatenated DataFrame with predictions followed by important sequences.\n",
    "                     Columns: ['ID', 'dataset', 'label_positive_probability', 'junction_aa', 'v_call', 'j_call']\n",
    "    \"\"\"\n",
    "    predictions_pattern = os.path.join(out_dir, '*_test_predictions.tsv')\n",
    "    sequences_pattern = os.path.join(out_dir, '*_important_sequences.tsv')\n",
    "\n",
    "    predictions_files = sorted(glob.glob(predictions_pattern))\n",
    "    sequences_files = sorted(glob.glob(sequences_pattern))\n",
    "\n",
    "    df_list = []\n",
    "\n",
    "    for pred_file in predictions_files:\n",
    "        try:\n",
    "            df = pd.read_csv(pred_file, sep='\\t')\n",
    "            df_list.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not read predictions file '{pred_file}'. Error: {e}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "    for seq_file in sequences_files:\n",
    "        try:\n",
    "            df = pd.read_csv(seq_file, sep='\\t')\n",
    "            df_list.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not read sequences file '{seq_file}'. Error: {e}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "    if not df_list:\n",
    "        print(\"Warning: No output files were found to concatenate.\")\n",
    "        concatenated_df = pd.DataFrame(\n",
    "            columns=['ID', 'dataset', 'label_positive_probability', 'junction_aa', 'v_call', 'j_call'])\n",
    "    else:\n",
    "        concatenated_df = pd.concat(df_list, ignore_index=True)\n",
    "    submissions_file = os.path.join(out_dir, 'submissions.csv')\n",
    "    concatenated_df.to_csv(submissions_file, index=False)\n",
    "    print(f\"Concatenated output written to `{submissions_file}`.\")\n",
    "\n",
    "\n",
    "def get_dataset_pairs(train_dir: str, test_dir: str) -> List[Tuple[str, List[str]]]:\n",
    "    \"\"\"Returns list of (train_path, [test_paths]) tuples for dataset pairs.\"\"\"\n",
    "    test_groups = defaultdict(list)\n",
    "    for test_name in sorted(os.listdir(test_dir)):\n",
    "        if test_name.startswith(\"test_dataset_\"):\n",
    "            base_id = test_name.replace(\"test_dataset_\", \"\").split(\"_\")[0]\n",
    "            test_groups[base_id].append(os.path.join(test_dir, test_name))\n",
    "\n",
    "    pairs = []\n",
    "    for train_name in sorted(os.listdir(train_dir)):\n",
    "        if train_name.startswith(\"train_dataset_\"):\n",
    "            train_id = train_name.replace(\"train_dataset_\", \"\")\n",
    "            train_path = os.path.join(train_dir, train_name)\n",
    "            pairs.append((train_path, test_groups.get(train_id, [])))\n",
    "\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44e0bff3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T10:04:48.713065Z",
     "iopub.status.busy": "2025-12-01T10:04:48.712676Z",
     "iopub.status.idle": "2025-12-01T10:04:48.737406Z",
     "shell.execute_reply": "2025-12-01T10:04:48.736421Z"
    },
    "papermill": {
     "duration": 0.031396,
     "end_time": "2025-12-01T10:04:48.738724",
     "exception": false,
     "start_time": "2025-12-01T10:04:48.707328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RepertoireLoader and PublicCloneDatabase defined\n"
     ]
    }
   ],
   "source": [
    "## === REPERTOIRE LOADER (must be defined first) ===\n",
    "\n",
    "class RepertoireLoader:\n",
    "    \"\"\"Simple, fast repertoire loader with memory-only caching.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._memory_cache = {}\n",
    "        \n",
    "    def load_repertoire(self, file_path: str, max_sequences: int = 10000) -> pd.DataFrame:\n",
    "        \"\"\"Load repertoire with memory caching.\"\"\"\n",
    "        cache_key = f\"{file_path}_{max_sequences}\"\n",
    "        \n",
    "        if cache_key in self._memory_cache:\n",
    "            return self._memory_cache[cache_key]\n",
    "        \n",
    "        # Read TSV - only essential columns for speed\n",
    "        try:\n",
    "            df = pd.read_csv(\n",
    "                file_path, sep='\\t',\n",
    "                usecols=lambda c: c in ['junction_aa', 'v_call', 'j_call', 'templates', 'duplicate_count'],\n",
    "                low_memory=True\n",
    "            )\n",
    "        except:\n",
    "            df = pd.read_csv(file_path, sep='\\t', low_memory=True)\n",
    "        \n",
    "        # Downsample if needed\n",
    "        if len(df) > max_sequences:\n",
    "            if 'templates' in df.columns:\n",
    "                df = df.nlargest(max_sequences, 'templates')\n",
    "            elif 'duplicate_count' in df.columns:\n",
    "                df = df.nlargest(max_sequences, 'duplicate_count')\n",
    "            else:\n",
    "                df = df.head(max_sequences)\n",
    "        \n",
    "        self._memory_cache[cache_key] = df\n",
    "        return df\n",
    "    \n",
    "    def clear_cache(self):\n",
    "        \"\"\"Clear memory cache.\"\"\"\n",
    "        self._memory_cache.clear()\n",
    "        gc.collect()\n",
    "\n",
    "# Global loader\n",
    "_LOADER = None\n",
    "\n",
    "def get_cache_loader(cache_dir: str = None) -> RepertoireLoader:\n",
    "    \"\"\"Get or create global loader.\"\"\"\n",
    "    global _LOADER\n",
    "    if _LOADER is None:\n",
    "        _LOADER = RepertoireLoader()\n",
    "    return _LOADER\n",
    "\n",
    "\n",
    "## === PUBLIC CLONE DATABASE ===\n",
    "\n",
    "class PublicCloneDatabase:\n",
    "    \"\"\"Fast database of discriminative CDR3 sequences.\"\"\"\n",
    "    \n",
    "    def __init__(self, min_occurrence: int = 3, cache_loader=None):\n",
    "        self.min_occurrence = min_occurrence\n",
    "        self.sequence_stats = {}\n",
    "        self.n_pos_reps = 0\n",
    "        self.n_neg_reps = 0\n",
    "        self.cache_loader = cache_loader or get_cache_loader()\n",
    "        \n",
    "    def fit(self, train_dir: str, max_sequences: int = 10000) -> 'PublicCloneDatabase':\n",
    "        \"\"\"Build database - optimized for speed.\"\"\"\n",
    "        metadata_path = os.path.join(train_dir, 'metadata.csv')\n",
    "        metadata = pd.read_csv(metadata_path)\n",
    "        \n",
    "        self.n_pos_reps = int((metadata['label_positive'] == 1).sum())\n",
    "        self.n_neg_reps = int((metadata['label_positive'] == 0).sum())\n",
    "        total_reps = self.n_pos_reps + self.n_neg_reps\n",
    "        \n",
    "        print(f\"Building clone database: {self.n_pos_reps} pos, {self.n_neg_reps} neg\")\n",
    "        \n",
    "        seq_in_pos = Counter()\n",
    "        seq_in_neg = Counter()\n",
    "        seq_info = {}\n",
    "        \n",
    "        n_files = len(metadata)\n",
    "        for i, (_, row) in enumerate(metadata.iterrows()):\n",
    "            file_path = os.path.join(train_dir, row['filename'])\n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(f\"  {i+1}/{n_files}...\")\n",
    "            \n",
    "            try:\n",
    "                rep_df = self.cache_loader.load_repertoire(file_path, max_sequences)\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            rep_df = rep_df.dropna(subset=['junction_aa'])\n",
    "            seqs = rep_df['junction_aa'].astype(str)\n",
    "            lengths = seqs.str.len()\n",
    "            valid_mask = (lengths >= 8) & (lengths <= 25)\n",
    "            valid_seqs = seqs[valid_mask].unique()\n",
    "            \n",
    "            if row['label_positive']:\n",
    "                seq_in_pos.update(valid_seqs)\n",
    "            else:\n",
    "                seq_in_neg.update(valid_seqs)\n",
    "            \n",
    "            # Store v/j for first 100 sequences\n",
    "            if 'v_call' in rep_df.columns:\n",
    "                for seq in list(valid_seqs)[:100]:\n",
    "                    if seq not in seq_info:\n",
    "                        match = rep_df[rep_df['junction_aa'] == seq].iloc[0]\n",
    "                        seq_info[seq] = {\n",
    "                            'v_call': str(match.get('v_call', 'unknown')),\n",
    "                            'j_call': str(match.get('j_call', 'unknown'))\n",
    "                        }\n",
    "        \n",
    "        # Score sequences\n",
    "        all_seqs = set(seq_in_pos.keys()) | set(seq_in_neg.keys())\n",
    "        print(f\"Scoring {len(all_seqs)} sequences...\")\n",
    "        \n",
    "        for seq in all_seqs:\n",
    "            n_pos = seq_in_pos.get(seq, 0)\n",
    "            n_neg = seq_in_neg.get(seq, 0)\n",
    "            total = n_pos + n_neg\n",
    "            \n",
    "            if total < self.min_occurrence or n_pos == 0:\n",
    "                continue\n",
    "            \n",
    "            pos_rate = n_pos / self.n_pos_reps\n",
    "            neg_rate = n_neg / self.n_neg_reps if self.n_neg_reps > 0 else 0\n",
    "            \n",
    "            if pos_rate <= neg_rate:\n",
    "                continue\n",
    "            \n",
    "            specificity = n_pos / (n_pos + n_neg)\n",
    "            coverage = n_pos / self.n_pos_reps\n",
    "            exp_pos = total * (self.n_pos_reps / total_reps)\n",
    "            chi2 = ((n_pos - exp_pos) ** 2 / (exp_pos + 0.1))\n",
    "            ensemble_score = 0.4 * specificity + 0.4 * min(coverage * 5, 1) + 0.2 * min(chi2 / 50, 1)\n",
    "            \n",
    "            info = seq_info.get(seq, {'v_call': 'unknown', 'j_call': 'unknown'})\n",
    "            self.sequence_stats[seq] = {\n",
    "                'ensemble_score': ensemble_score,\n",
    "                'specificity': specificity,\n",
    "                'coverage': coverage,\n",
    "                'n_pos': n_pos,\n",
    "                'n_neg': n_neg,\n",
    "                'v_call': info['v_call'],\n",
    "                'j_call': info['j_call']\n",
    "            }\n",
    "        \n",
    "        print(f\"âœ… {len(self.sequence_stats)} discriminative sequences\")\n",
    "        return self\n",
    "    \n",
    "    def get_enrichment_features(self, rep_df: pd.DataFrame) -> Dict[str, float]:\n",
    "        \"\"\"Get enrichment features for a repertoire.\"\"\"\n",
    "        default = {'n_public_seqs': 0.0, 'frac_public_seqs': 0.0, \n",
    "                   'ensemble_score_mean': 0.0, 'specificity_mean': 0.0}\n",
    "        \n",
    "        if not self.sequence_stats:\n",
    "            return default\n",
    "        \n",
    "        unique_seqs = set(rep_df['junction_aa'].dropna().unique())\n",
    "        public_seqs = unique_seqs & set(self.sequence_stats.keys())\n",
    "        \n",
    "        if not public_seqs:\n",
    "            return default\n",
    "        \n",
    "        scores = [self.sequence_stats[s]['ensemble_score'] for s in public_seqs]\n",
    "        specs = [self.sequence_stats[s]['specificity'] for s in public_seqs]\n",
    "        \n",
    "        return {\n",
    "            'n_public_seqs': float(len(public_seqs)),\n",
    "            'frac_public_seqs': float(len(public_seqs) / len(unique_seqs)),\n",
    "            'ensemble_score_mean': float(np.mean(scores)),\n",
    "            'specificity_mean': float(np.mean(specs))\n",
    "        }\n",
    "    \n",
    "    def get_top_sequences(self, top_k: int = 50000, dataset_name: str = '') -> pd.DataFrame:\n",
    "        \"\"\"Get top discriminative sequences.\"\"\"\n",
    "        sorted_seqs = sorted(\n",
    "            self.sequence_stats.items(),\n",
    "            key=lambda x: x[1]['ensemble_score'],\n",
    "            reverse=True\n",
    "        )[:top_k]\n",
    "        \n",
    "        records = []\n",
    "        for i, (seq, stats) in enumerate(sorted_seqs):\n",
    "            records.append({\n",
    "                'ID': f'{dataset_name}_seq_{i+1}' if dataset_name else f'seq_{i+1}',\n",
    "                'dataset': dataset_name,\n",
    "                'label_positive_probability': -999.0,\n",
    "                'junction_aa': seq,\n",
    "                'v_call': stats['v_call'],\n",
    "                'j_call': stats['j_call']\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(records)\n",
    "\n",
    "print(\"âœ… RepertoireLoader and PublicCloneDatabase defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3abb6e98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T10:04:48.747405Z",
     "iopub.status.busy": "2025-12-01T10:04:48.747069Z",
     "iopub.status.idle": "2025-12-01T10:04:48.771960Z",
     "shell.execute_reply": "2025-12-01T10:04:48.771023Z"
    },
    "papermill": {
     "duration": 0.031016,
     "end_time": "2025-12-01T10:04:48.773341",
     "exception": false,
     "start_time": "2025-12-01T10:04:48.742325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Feature extraction defined\n"
     ]
    }
   ],
   "source": [
    "## === FEATURE EXTRACTION ===\n",
    "\n",
    "AMINO_ACIDS = list('ACDEFGHIKLMNPQRSTVWY')\n",
    "\n",
    "def extract_repertoire_features(rep_df: pd.DataFrame, clone_db=None) -> Dict[str, float]:\n",
    "    \"\"\"Extract features from a single TCR repertoire - FAST version.\"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    rep_df = rep_df.dropna(subset=['junction_aa'])\n",
    "    seqs = rep_df['junction_aa']\n",
    "    \n",
    "    if len(seqs) == 0:\n",
    "        return {'empty': 1.0}\n",
    "    \n",
    "    # CDR3 LENGTH (6 features)\n",
    "    lengths = seqs.str.len()\n",
    "    features['len_mean'] = float(lengths.mean())\n",
    "    features['len_std'] = float(lengths.std()) if len(lengths) > 1 else 0.0\n",
    "    features['len_median'] = float(lengths.median())\n",
    "    features['len_short_frac'] = float((lengths < 10).mean())\n",
    "    features['len_long_frac'] = float((lengths > 18).mean())\n",
    "    features['len_skew'] = float(skew(lengths)) if len(lengths) > 2 else 0.0\n",
    "    \n",
    "    # DIVERSITY (4 features)\n",
    "    seq_counts = seqs.value_counts()\n",
    "    probs = seq_counts / seq_counts.sum()\n",
    "    features['entropy'] = float(entropy(probs))\n",
    "    features['richness'] = float(len(seq_counts) / len(rep_df))\n",
    "    features['simpson'] = float(1 - np.sum(probs ** 2))\n",
    "    features['n_unique'] = float(len(seq_counts))\n",
    "    \n",
    "    # CLONALITY (4 features)\n",
    "    sorted_counts = np.sort(seq_counts.values)[::-1]\n",
    "    total = sorted_counts.sum()\n",
    "    if total > 0:\n",
    "        features['top1_frac'] = float(sorted_counts[0] / total)\n",
    "        features['top10_frac'] = float(sorted_counts[:min(10, len(sorted_counts))].sum() / total)\n",
    "        features['top100_frac'] = float(sorted_counts[:min(100, len(sorted_counts))].sum() / total)\n",
    "    else:\n",
    "        features['top1_frac'] = 0.0\n",
    "        features['top10_frac'] = 0.0\n",
    "        features['top100_frac'] = 0.0\n",
    "    \n",
    "    # Gini coefficient\n",
    "    if len(sorted_counts) > 1 and total > 0:\n",
    "        n = len(sorted_counts)\n",
    "        features['gini'] = float((2 * np.sum((np.arange(1, n+1) * sorted_counts)) - (n + 1) * total) / (n * total))\n",
    "    else:\n",
    "        features['gini'] = 0.0\n",
    "    \n",
    "    # V GENE (4 features)\n",
    "    if 'v_call' in rep_df.columns:\n",
    "        v_calls = rep_df['v_call'].dropna()\n",
    "        if len(v_calls) > 0:\n",
    "            v_counts = v_calls.value_counts(normalize=True)\n",
    "            features['n_v'] = float(len(v_counts))\n",
    "            features['v_entropy'] = float(entropy(v_counts))\n",
    "            features['v_top1'] = float(v_counts.iloc[0])\n",
    "        else:\n",
    "            features['n_v'] = 0.0\n",
    "            features['v_entropy'] = 0.0\n",
    "            features['v_top1'] = 0.0\n",
    "    else:\n",
    "        features['n_v'] = 0.0\n",
    "        features['v_entropy'] = 0.0\n",
    "        features['v_top1'] = 0.0\n",
    "    \n",
    "    # J GENE (3 features)\n",
    "    if 'j_call' in rep_df.columns:\n",
    "        j_calls = rep_df['j_call'].dropna()\n",
    "        if len(j_calls) > 0:\n",
    "            j_counts = j_calls.value_counts(normalize=True)\n",
    "            features['n_j'] = float(len(j_counts))\n",
    "            features['j_entropy'] = float(entropy(j_counts))\n",
    "            features['j_top1'] = float(j_counts.iloc[0])\n",
    "        else:\n",
    "            features['n_j'] = 0.0\n",
    "            features['j_entropy'] = 0.0\n",
    "            features['j_top1'] = 0.0\n",
    "    else:\n",
    "        features['n_j'] = 0.0\n",
    "        features['j_entropy'] = 0.0\n",
    "        features['j_top1'] = 0.0\n",
    "    \n",
    "    # AA COMPOSITION (simplified - 5 features)\n",
    "    all_aa = ''.join(seqs.astype(str))\n",
    "    aa_counts = Counter(all_aa)\n",
    "    total_aa = sum(aa_counts.values())\n",
    "    if total_aa > 0:\n",
    "        # Hydrophobic fraction\n",
    "        hydrophobic = set('AILMFVPG')\n",
    "        features['hydrophobic_frac'] = sum(aa_counts.get(aa, 0) for aa in hydrophobic) / total_aa\n",
    "        # Charged fraction\n",
    "        charged = set('DEKR')\n",
    "        features['charged_frac'] = sum(aa_counts.get(aa, 0) for aa in charged) / total_aa\n",
    "        # Polar fraction\n",
    "        polar = set('STNQCY')\n",
    "        features['polar_frac'] = sum(aa_counts.get(aa, 0) for aa in polar) / total_aa\n",
    "        # Aromatic fraction\n",
    "        aromatic = set('FWY')\n",
    "        features['aromatic_frac'] = sum(aa_counts.get(aa, 0) for aa in aromatic) / total_aa\n",
    "        # Cysteine (important for structure)\n",
    "        features['cys_frac'] = aa_counts.get('C', 0) / total_aa\n",
    "    else:\n",
    "        features['hydrophobic_frac'] = 0.0\n",
    "        features['charged_frac'] = 0.0\n",
    "        features['polar_frac'] = 0.0\n",
    "        features['aromatic_frac'] = 0.0\n",
    "        features['cys_frac'] = 0.0\n",
    "    \n",
    "    # ENRICHMENT from clone database\n",
    "    if clone_db is not None:\n",
    "        enrich = clone_db.get_enrichment_features(rep_df)\n",
    "        features.update(enrich)\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "def extract_all_features(data_dir: str, clone_db=None, cache_loader=None, \n",
    "                         max_sequences: int = 10000) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "    \"\"\"Extract features for all repertoires - FAST.\"\"\"\n",
    "    cache_loader = cache_loader or get_cache_loader()\n",
    "    metadata_path = os.path.join(data_dir, 'metadata.csv')\n",
    "    has_labels = os.path.exists(metadata_path)\n",
    "    \n",
    "    feature_records = []\n",
    "    labels = []\n",
    "    repertoire_ids = []\n",
    "    \n",
    "    if has_labels:\n",
    "        metadata = pd.read_csv(metadata_path)\n",
    "        n_files = len(metadata)\n",
    "        print(f\"Extracting features from {n_files} repertoires...\")\n",
    "        \n",
    "        for i, (_, row) in enumerate(metadata.iterrows()):\n",
    "            if (i + 1) % 20 == 0:\n",
    "                print(f\"  {i+1}/{n_files}...\")\n",
    "            \n",
    "            file_path = os.path.join(data_dir, row['filename'])\n",
    "            try:\n",
    "                rep_df = cache_loader.load_repertoire(file_path, max_sequences)\n",
    "                features = extract_repertoire_features(rep_df, clone_db)\n",
    "                feature_records.append(features)\n",
    "                labels.append(row['label_positive'])\n",
    "                repertoire_ids.append(row['repertoire_id'])\n",
    "            except:\n",
    "                continue\n",
    "    else:\n",
    "        tsv_files = sorted(glob.glob(os.path.join(data_dir, '*.tsv')))\n",
    "        n_files = len(tsv_files)\n",
    "        print(f\"Extracting features from {n_files} test files...\")\n",
    "        \n",
    "        for i, file_path in enumerate(tsv_files):\n",
    "            if (i + 1) % 20 == 0:\n",
    "                print(f\"  {i+1}/{n_files}...\")\n",
    "            \n",
    "            try:\n",
    "                rep_df = cache_loader.load_repertoire(file_path, max_sequences)\n",
    "                features = extract_repertoire_features(rep_df, clone_db)\n",
    "                feature_records.append(features)\n",
    "                repertoire_ids.append(os.path.basename(file_path).replace('.tsv', ''))\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    print(f\"âœ… {len(feature_records)} repertoires processed\")\n",
    "    \n",
    "    X = pd.DataFrame(feature_records)\n",
    "    X.index = repertoire_ids\n",
    "    \n",
    "    if has_labels:\n",
    "        return X, pd.Series(labels, index=repertoire_ids)\n",
    "    return X, None\n",
    "\n",
    "print(\"âœ… Feature extraction defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73758c44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T10:04:48.781553Z",
     "iopub.status.busy": "2025-12-01T10:04:48.781234Z",
     "iopub.status.idle": "2025-12-01T10:04:48.799639Z",
     "shell.execute_reply": "2025-12-01T10:04:48.798314Z"
    },
    "papermill": {
     "duration": 0.024303,
     "end_time": "2025-12-01T10:04:48.801069",
     "exception": false,
     "start_time": "2025-12-01T10:04:48.776766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… SimpleEnsemble defined\n"
     ]
    }
   ],
   "source": [
    "## === MODEL TRAINING (Anti-Overfitting) ===\n",
    "\n",
    "class SimpleEnsemble:\n",
    "    \"\"\"\n",
    "    Simple, fast ensemble with anti-overfitting configuration.\n",
    "    Tracks train vs val AUC to detect overfitting.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_folds: int = 5):\n",
    "        self.n_folds = n_folds\n",
    "        self.models = []\n",
    "        self.cv_results = []\n",
    "        self.feature_names = None\n",
    "        \n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series) -> 'SimpleEnsemble':\n",
    "        \"\"\"Train with CV and overfitting detection.\"\"\"\n",
    "        self.feature_names = X.columns.tolist()\n",
    "        \n",
    "        print(f\"\\nTraining ensemble ({self.n_folds}-fold CV)...\")\n",
    "        print(f\"Data: {len(X)} samples, {len(self.feature_names)} features\")\n",
    "        print(f\"Classes: {int(y.sum())} pos / {int(len(y)-y.sum())} neg\")\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=self.n_folds, shuffle=True, random_state=42)\n",
    "        \n",
    "        oof_preds = np.zeros(len(y))\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            \n",
    "            # ANTI-OVERFITTING LightGBM config\n",
    "            model = lgb.LGBMClassifier(\n",
    "                n_estimators=1000,\n",
    "                num_leaves=8,          # Very few leaves\n",
    "                max_depth=3,           # Very shallow\n",
    "                learning_rate=0.01,    # Slow learning\n",
    "                feature_fraction=0.5,  # Feature dropout\n",
    "                bagging_fraction=0.5,  # Sample dropout\n",
    "                bagging_freq=1,\n",
    "                lambda_l1=5.0,         # Strong L1\n",
    "                lambda_l2=5.0,         # Strong L2\n",
    "                min_child_samples=20,  # Need more samples per leaf\n",
    "                random_state=42,\n",
    "                verbose=-1,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            model.fit(\n",
    "                X_train, y_train,\n",
    "                eval_set=[(X_val, y_val)],\n",
    "                callbacks=[lgb.early_stopping(30, verbose=False)]\n",
    "            )\n",
    "            \n",
    "            self.models.append(model)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            train_pred = model.predict_proba(X_train)[:, 1]\n",
    "            val_pred = model.predict_proba(X_val)[:, 1]\n",
    "            oof_preds[val_idx] = val_pred\n",
    "            \n",
    "            train_auc = roc_auc_score(y_train, train_pred)\n",
    "            val_auc = roc_auc_score(y_val, val_pred)\n",
    "            gap = train_auc - val_auc\n",
    "            \n",
    "            # Overfitting diagnosis\n",
    "            if gap > 0.15:\n",
    "                status = \"ðŸ”´ SEVERE OVERFIT\"\n",
    "            elif gap > 0.08:\n",
    "                status = \"ðŸŸ¡ MODERATE OVERFIT\"\n",
    "            elif gap > 0.03:\n",
    "                status = \"ðŸŸ¢ MILD OVERFIT\"\n",
    "            else:\n",
    "                status = \"âœ… GOOD\"\n",
    "            \n",
    "            print(f\"Fold {fold+1}: Train={train_auc:.4f} Val={val_auc:.4f} Gap={gap:.4f} {status}\")\n",
    "            \n",
    "            self.cv_results.append({\n",
    "                'fold': fold + 1,\n",
    "                'train_auc': train_auc,\n",
    "                'val_auc': val_auc,\n",
    "                'overfit_gap': gap,\n",
    "                'pred_std': val_pred.std()\n",
    "            })\n",
    "        \n",
    "        # Overall metrics\n",
    "        overall_auc = roc_auc_score(y, oof_preds)\n",
    "        avg_gap = np.mean([r['overfit_gap'] for r in self.cv_results])\n",
    "        \n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Overall OOF AUC: {overall_auc:.4f}\")\n",
    "        print(f\"Average Overfit Gap: {avg_gap:.4f}\")\n",
    "        \n",
    "        if avg_gap > 0.15:\n",
    "            print(\"âš ï¸  SEVERE OVERFITTING - consider simpler model\")\n",
    "        elif avg_gap > 0.08:\n",
    "            print(\"âš ï¸  MODERATE OVERFITTING\")\n",
    "        else:\n",
    "            print(\"âœ… Generalization looks OK\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X: pd.DataFrame) -> np.ndarray:\n",
    "        \"\"\"Predict with ensemble averaging.\"\"\"\n",
    "        # Align features\n",
    "        for col in self.feature_names:\n",
    "            if col not in X.columns:\n",
    "                X[col] = 0.0\n",
    "        X = X[self.feature_names].fillna(0)\n",
    "        \n",
    "        preds = np.zeros(len(X))\n",
    "        for model in self.models:\n",
    "            preds += model.predict_proba(X)[:, 1]\n",
    "        return preds / len(self.models)\n",
    "    \n",
    "    def get_cv_results(self) -> pd.DataFrame:\n",
    "        return pd.DataFrame(self.cv_results)\n",
    "\n",
    "print(\"âœ… SimpleEnsemble defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bc20294",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T10:04:48.809790Z",
     "iopub.status.busy": "2025-12-01T10:04:48.809314Z",
     "iopub.status.idle": "2025-12-01T10:04:48.824786Z",
     "shell.execute_reply": "2025-12-01T10:04:48.823556Z"
    },
    "papermill": {
     "duration": 0.021891,
     "end_time": "2025-12-01T10:04:48.826553",
     "exception": false,
     "start_time": "2025-12-01T10:04:48.804662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ImmuneStatePredictor defined\n"
     ]
    }
   ],
   "source": [
    "## === MAIN PREDICTOR CLASS ===\n",
    "\n",
    "class ImmuneStatePredictor:\n",
    "    \"\"\"Fast TCR repertoire classifier with overfitting protection.\"\"\"\n",
    "    \n",
    "    def __init__(self, n_jobs: int = 1, **kwargs):\n",
    "        self.n_jobs = n_jobs\n",
    "        self.clone_db = None\n",
    "        self.ensemble = None\n",
    "        self.feature_names = None\n",
    "        self.important_sequences_ = None\n",
    "        self.train_dataset_name = None\n",
    "        self.cache_loader = get_cache_loader()\n",
    "        \n",
    "        self.n_folds = kwargs.get('n_folds', 5)\n",
    "        self.max_sequences = kwargs.get('max_sequences', 10000)\n",
    "    \n",
    "    def fit(self, train_dir: str) -> 'ImmuneStatePredictor':\n",
    "        \"\"\"Train the classifier.\"\"\"\n",
    "        self.train_dataset_name = os.path.basename(train_dir)\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"TRAINING: {self.train_dataset_name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # 1. Build clone database\n",
    "        print(\"\\n[1/3] Building clone database...\")\n",
    "        self.clone_db = PublicCloneDatabase(cache_loader=self.cache_loader)\n",
    "        self.clone_db.fit(train_dir, self.max_sequences)\n",
    "        \n",
    "        # 2. Extract features\n",
    "        print(\"\\n[2/3] Extracting features...\")\n",
    "        X, y = extract_all_features(\n",
    "            train_dir, \n",
    "            clone_db=self.clone_db,\n",
    "            cache_loader=self.cache_loader,\n",
    "            max_sequences=self.max_sequences\n",
    "        )\n",
    "        X = X.fillna(0)\n",
    "        self.feature_names = X.columns.tolist()\n",
    "        \n",
    "        # 3. Train ensemble\n",
    "        print(\"\\n[3/3] Training ensemble...\")\n",
    "        self.ensemble = SimpleEnsemble(n_folds=self.n_folds)\n",
    "        self.ensemble.fit(X, y)\n",
    "        \n",
    "        # Get important sequences\n",
    "        self.important_sequences_ = self.clone_db.get_top_sequences(\n",
    "            top_k=50000, \n",
    "            dataset_name=self.train_dataset_name\n",
    "        )\n",
    "        \n",
    "        # Cleanup\n",
    "        self.cache_loader.clear_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"TRAINING COMPLETE\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self, test_dir: str) -> pd.DataFrame:\n",
    "        \"\"\"Predict probabilities for test data.\"\"\"\n",
    "        print(f\"Predicting: {os.path.basename(test_dir)}...\")\n",
    "        \n",
    "        X_test, _ = extract_all_features(\n",
    "            test_dir,\n",
    "            clone_db=self.clone_db,\n",
    "            cache_loader=self.cache_loader,\n",
    "            max_sequences=self.max_sequences\n",
    "        )\n",
    "        X_test = X_test.fillna(0)\n",
    "        \n",
    "        preds = self.ensemble.predict(X_test)\n",
    "        \n",
    "        test_name = os.path.basename(test_dir)\n",
    "        result = pd.DataFrame({\n",
    "            'ID': X_test.index.tolist(),\n",
    "            'dataset': test_name,\n",
    "            'label_positive_probability': preds,\n",
    "            'junction_aa': -999.0,\n",
    "            'v_call': -999.0,\n",
    "            'j_call': -999.0\n",
    "        })\n",
    "        \n",
    "        print(f\"  Done: range [{preds.min():.3f}, {preds.max():.3f}]\")\n",
    "        return result\n",
    "    \n",
    "    def get_cv_results(self) -> pd.DataFrame:\n",
    "        if self.ensemble:\n",
    "            return self.ensemble.get_cv_results()\n",
    "        return None\n",
    "\n",
    "print(\"âœ… ImmuneStatePredictor defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d1d5da9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T10:04:48.835907Z",
     "iopub.status.busy": "2025-12-01T10:04:48.835562Z",
     "iopub.status.idle": "2025-12-01T10:06:16.785418Z",
     "shell.execute_reply": "2025-12-01T10:06:16.784330Z"
    },
    "papermill": {
     "duration": 87.956794,
     "end_time": "2025-12-01T10:06:16.787103",
     "exception": false,
     "start_time": "2025-12-01T10:04:48.830309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: train_dataset_1\n",
      "\n",
      "============================================================\n",
      "TRAINING: train_dataset_1\n",
      "============================================================\n",
      "\n",
      "[1/3] Building clone database...\n",
      "Building clone database: 200 pos, 200 neg\n",
      "  10/400...\n",
      "  20/400...\n",
      "  30/400...\n",
      "  40/400...\n",
      "  50/400...\n",
      "  60/400...\n",
      "  70/400...\n",
      "  80/400...\n",
      "  90/400...\n",
      "  100/400...\n",
      "  110/400...\n",
      "  120/400...\n",
      "  130/400...\n",
      "  140/400...\n",
      "  150/400...\n",
      "  160/400...\n",
      "  170/400...\n",
      "  180/400...\n",
      "  190/400...\n",
      "  200/400...\n",
      "  210/400...\n",
      "  220/400...\n",
      "  230/400...\n",
      "  240/400...\n",
      "  250/400...\n",
      "  260/400...\n",
      "  270/400...\n",
      "  280/400...\n",
      "  290/400...\n",
      "  300/400...\n",
      "  310/400...\n",
      "  320/400...\n",
      "  330/400...\n",
      "  340/400...\n",
      "  350/400...\n",
      "  360/400...\n",
      "  370/400...\n",
      "  380/400...\n",
      "  390/400...\n",
      "  400/400...\n",
      "Scoring 3260730 sequences...\n",
      "âœ… 33582 discriminative sequences\n",
      "\n",
      "[2/3] Extracting features...\n",
      "Extracting features from 400 repertoires...\n",
      "  20/400...\n",
      "  40/400...\n",
      "  60/400...\n",
      "  80/400...\n",
      "  100/400...\n",
      "  120/400...\n",
      "  140/400...\n",
      "  160/400...\n",
      "  180/400...\n",
      "  200/400...\n",
      "  220/400...\n",
      "  240/400...\n",
      "  260/400...\n",
      "  280/400...\n",
      "  300/400...\n",
      "  320/400...\n",
      "  340/400...\n",
      "  360/400...\n",
      "  380/400...\n",
      "  400/400...\n",
      "âœ… 400 repertoires processed\n",
      "\n",
      "[3/3] Training ensemble...\n",
      "\n",
      "Training ensemble (5-fold CV)...\n",
      "Data: 400 samples, 29 features\n",
      "Classes: 200 pos / 200 neg\n",
      "Fold 1: Train=1.0000 Val=1.0000 Gap=0.0000 âœ… GOOD\n",
      "Fold 2: Train=1.0000 Val=1.0000 Gap=0.0000 âœ… GOOD\n",
      "Fold 3: Train=1.0000 Val=1.0000 Gap=0.0000 âœ… GOOD\n",
      "Fold 4: Train=1.0000 Val=1.0000 Gap=0.0000 âœ… GOOD\n",
      "Fold 5: Train=1.0000 Val=1.0000 Gap=0.0000 âœ… GOOD\n",
      "\n",
      "==================================================\n",
      "Overall OOF AUC: 1.0000\n",
      "Average Overfit Gap: 0.0000\n",
      "âœ… Generalization looks OK\n",
      "\n",
      "============================================================\n",
      "TRAINING COMPLETE\n",
      "============================================================\n",
      "\n",
      "\n",
      "CV Results:\n",
      " fold  train_auc  val_auc  overfit_gap  pred_std\n",
      "    1        1.0      1.0          0.0  0.436348\n",
      "    2        1.0      1.0          0.0  0.436889\n",
      "    3        1.0      1.0          0.0  0.432829\n",
      "    4        1.0      1.0          0.0  0.435082\n",
      "    5        1.0      1.0          0.0  0.437274\n"
     ]
    }
   ],
   "source": [
    "## === TEST ON SINGLE DATASET ===\n",
    "\n",
    "# Kaggle paths\n",
    "train_dir_base = \"/kaggle/input/adaptive-immune-profiling-challenge-2025/train_datasets/train_datasets\"\n",
    "test_dir_base = \"/kaggle/input/adaptive-immune-profiling-challenge-2025/test_datasets/test_datasets\"\n",
    "results_dir = \"/kaggle/working/results\"\n",
    "\n",
    "# Get dataset pairs\n",
    "pairs = get_dataset_pairs(train_dir_base, test_dir_base)\n",
    "\n",
    "if pairs:\n",
    "    train_dir, test_dirs = pairs[0]  # First dataset only\n",
    "    print(f\"Testing: {os.path.basename(train_dir)}\")\n",
    "    \n",
    "    predictor = ImmuneStatePredictor(n_jobs=4, n_folds=5, max_sequences=10000)\n",
    "    predictor.fit(train_dir)\n",
    "    \n",
    "    # Show CV results\n",
    "    cv = predictor.get_cv_results()\n",
    "    if cv is not None:\n",
    "        print(\"\\nCV Results:\")\n",
    "        print(cv.to_string(index=False))\n",
    "else:\n",
    "    print(\"No datasets found!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 13374319,
     "sourceId": 106680,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 111.37354,
   "end_time": "2025-12-01T10:06:19.022864",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-01T10:04:27.649324",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
